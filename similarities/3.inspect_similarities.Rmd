---
title: "Inspect similarities"
output:
  html_notebook:
    toc: yes
    toc_float: yes
    toc_depth: 3
    number_sections: yes
    theme: lumen
params:
  batch: "2020_11_04_CPJUMP1"
  experiment: 
    value:
      Metadata_experiment_condition: Standard
  strata:
    value:
      - Metadata_experiment_condition
      - Metadata_experiment_type
      - Metadata_cell_line
      - Metadata_timepoint
  data_level: normalized_feature_select_outlier_trimmed
  normalization: whole_plate
  similarity_method: cosine
---

# Setup

```{r message=FALSE}
library(magrittr)
library(tidyverse)
library(glue)
library(arrow)
library(matric)
library(logger)
source("utils.R")
log_layout(layout_no_timestamp)
```


```{r}
process_notebook_params(params)

log_info("Comparison tag = {comparision_tag}")

log_info("Normalization = {normalization}. Using suffix = '{norm_suffix}'")

log_info("Batch = {batch}")

log_info("Data level = {data_level}")

log_info("Data level tag = {data_level_tag}")

log_info("Similarity method = {similarity_method}")

log_info("Filename prefix = {filename_prefix}")
```

# Load metrics

```{r}
metric_set_names <- c(
  "level_1_metrics",
  "level_2_1_metrics",
  "level_1_and_2_1_metrics"
)

metric_sets <- 
  map(metric_set_names, function(metric_set) {
  parquet_file <-
    glue("{batch}/{filename_prefix}_sim_{similarity_method}_{metric_set}.parquet")
  
  futile.logger::flog.info(glue("Reading {parquet_file} ..."))
  
  arrow::read_parquet(glue(parquet_file))
  
})

names(metric_sets) <- metric_set_names

parquet_file <-
  glue("{batch}/{filename_prefix}_sim_{similarity_method}_collated.parquet")

futile.logger::flog.info(glue("Reading {parquet_file} ..."))

collated_sim <-
  arrow::read_parquet(glue(parquet_file))

# TODO: `all_same_cols_rep` should be stored with the metrics files
all_same_cols_rep <- attr(collated_sim, "all_same_cols_rep")

rm(collated_sim)
```

# Load cell counts

```{r}
parquet_file <- glue("../collated/{batch}/{batch}_all_augmented.parquet")

futile.logger::flog.info(glue("Loading {parquet_file} ..."))

stopifnot(file.exists(parquet_file))

cell_count_df <-
  read_parquet(parquet_file, col_select = matches("Metadata_|Cells_Number_Object_Number")) %>%
  mutate(across(matches("Metadata"), as.character)) %>%
  select(matches("Metadata_"), cell_count = Cells_Number_Object_Number) %>%
  inner_join(experiment) %>%
  group_by(across(all_of(all_same_cols_rep))) %>%
  summarise(cell_count = median(cell_count), .groups = "keep") %>%
  ungroup() %>%
  select(
    Metadata_experiment_condition, 
    Metadata_experiment_type, 
    Metadata_cell_line, 
    Metadata_timepoint, 
    Metadata_Well, 
    cell_count)

#     Metadata_broad_sample was dropped because the upstream metadata has not yet been fixed. It should be added back!

```

# Inspect metrics

## Functions

```{r}
plot_metric_v_cellcount <- 
  function(metrics,
           metric_name, 
           plot_title) {
    
  # metrics <- level_1_metrics
  # metric_name <- "sim_scaled_mean_ref_i_mean_i"
  # plot_title <- experiment_tag
    
  metric_sym <- sym(metric_name)

  x_threshold <- 
    metrics %>%
    filter(Metadata_negcon_or_other == "negcon") %>%
    group_by(Metadata_experiment_type,
             Metadata_cell_line,
             Metadata_timepoint) %>%
    summarise(
      cell_count_thresh =
        mean(cell_count) - 3 * sd(cell_count),
      .groups = "keep"
    )
  
  y_threshold <-
    metrics %>%
    filter(Metadata_negcon_or_other == "negcon") %>%
    group_by(Metadata_experiment_type,
             Metadata_cell_line,
             Metadata_timepoint) %>%
    summarise(
      metric_thresh =
        mean(!!metric_sym) + 3 * sd(!!metric_sym),
      .groups = "keep"
    )
  
  frac_non_negcon_above_y_threshold <-
    metrics %>%
    inner_join(y_threshold) %>%
    filter(Metadata_negcon_or_other != "negcon") %>%
    group_by(Metadata_experiment_type,
             Metadata_cell_line,
             Metadata_timepoint) %>%
    mutate(is_above_thresh = (!!metric_sym) > metric_thresh) %>%
    summarise(
      n_pert_strong =
        sum(is_above_thresh),
      n_pert = n(),
      pc_pert_strong = round(n_pert_strong / n_pert, 2),
      .groups = "keep"
    ) %>%
    rename_with(~str_remove_all(., "Metadata_"))
  
  frac_above_y_threshold <-
    metrics %>%
    inner_join(y_threshold) %>%
    group_by(Metadata_experiment_type,
             Metadata_cell_line,
             Metadata_timepoint) %>%
    mutate(is_above_thresh = (!!metric_sym) > metric_thresh) %>%
    summarise(
      n_all_strong =
        sum(is_above_thresh),
      n_all = n(),
      pc_all_strong = round(n_all_strong / n_all, 2),
      .groups = "keep"
    ) %>%
    rename_with(~str_remove_all(., "Metadata_"))

    
  p <- 
    metrics %>%
    mutate(point_order = as.numeric(factor(Metadata_negcon_or_other, levels = c("empty", "negcon", "pert"), ordered = TRUE))) %>%
    arrange(desc(point_order)) %>%
    ggplot(aes(cell_count, 
               !!metric_sym, 
               color = Metadata_negcon_or_other)) + 
    geom_point() + 
    scale_colour_manual(values = c("empty" = "green", "negcon" = "red", "pert" = "black")) + 
    facet_wrap(Metadata_experiment_type~Metadata_timepoint~Metadata_cell_line, ncol = 2) + 
    geom_hline(data = y_threshold, aes(yintercept = metric_thresh), alpha = 0.5) +
    geom_vline(data = x_threshold, aes(xintercept = cell_count_thresh), alpha = 0.5) +
    ggtitle(plot_title) + 
    theme(legend.position = "bottom")
  
  list(fig1 = p,
       table1 = frac_non_negcon_above_y_threshold,
       table2 = frac_above_y_threshold)

}
```

```{r}
knitr::opts_chunk$set(fig.height = 12, fig.width = 6, rows.print = 20)
```

## Process metrics

### Level 1


```{r}
level_1_metrics <- 
  metric_sets[["level_1_metrics"]]
```


```{r}
level_1_metrics %>%
  group_by(across(all_of(c(strata, "Metadata_negcon_or_other")))) %>%
  rename_with(~str_remove_all(., "Metadata_")) %>%
  tally()
```

Confirm that all rows have cell counts associated with them

```{r}
level_1_metrics %>%
  anti_join(cell_count_df)
```

Join with cell count

```{r}
level_1_metrics <- 
  level_1_metrics %>%
  inner_join(cell_count_df)
```


### Level 2

```{r}
level_1_and_2_1_metrics <- 
  metric_sets[["level_1_and_2_1_metrics"]]
```

Confirm that all rows have cell counts associated with them

```{r}
level_1_and_2_1_metrics %>%
  anti_join(cell_count_df)
```

Join with cell count

```{r}
level_1_and_2_1_metrics <-
  level_1_and_2_1_metrics %>%
  inner_join(cell_count_df)
```


## Plot metrics

### Level 1


```{r}
result <-
  plot_metric_v_cellcount(level_1_metrics, "sim_mean_i_mean_i", experiment_tag)
result$fig1
result$table1
result$table2
```


```{r}
result <-
  plot_metric_v_cellcount(level_1_metrics,
                          "sim_scaled_mean_non_rep_i_mean_i",
                          experiment_tag)
result$fig1
result$table1
result$table2
```


```{r}
result <-
  plot_metric_v_cellcount(level_1_metrics,
                          "sim_scaled_mean_ref_i_mean_i",
                          experiment_tag)
result$fig1
result$table1
result$table2
```


### Level 1 and 2_1 


```{r}
result <-
  plot_metric_v_cellcount(level_1_and_2_1_metrics, "sim_mean_g", experiment_tag)
result$fig1
result$table1
result$table2
```


```{r}
result <-
  plot_metric_v_cellcount(level_1_and_2_1_metrics,
                          "sim_scaled_mean_non_rep_g",
                          experiment_tag)
result$fig1
result$table1
result$table2
```


```{r}
result <-
  plot_metric_v_cellcount(level_1_and_2_1_metrics,
                          "sim_scaled_mean_ref_g",
                          experiment_tag)
result$fig1
result$table1
result$table2
```

