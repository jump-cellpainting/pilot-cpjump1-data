---
title: "Sample images"
output:
  html_notebook:
    toc: yes
    toc_float: yes
    toc_depth: 3
    number_sections: yes
    theme: lumen
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
params:
  force_recompute: FALSE
  batch: 2020_11_04_CPJUMP1
  data_level: normalized
  normalization: negcon
  experiment: 
    value:
      Metadata_experiment_condition: Standard
      Metadata_experiment_type: Compound
      Metadata_cell_line: U2OS
      Metadata_timepoint: "48"
  nesting_level_0:
    value:
      - Metadata_experiment_condition
      - Metadata_experiment_type
      - Metadata_cell_line
      - Metadata_timepoint
  strata_replicate:
    value:
      - Metadata_experiment_condition
      - Metadata_experiment_type
      - Metadata_cell_line
      - Metadata_timepoint
      - Metadata_plate_map_name
      - Metadata_Well
      - Metadata_genes
      - Metadata_pert_type
      - Metadata_control_type
      - Metadata_Plate_Map_Name
      - Metadata_negcon_control_type
      - Metadata_target_sequence
      - Metadata_mg_per_ml
      - Metadata_mmoles_per_liter
      - Metadata_solvent
      - Metadata_target
      - Metadata_pert_iname
      - Metadata_broad_sample
      - Metadata_pubchem_cid
      - Metadata_InChIKey
      - Metadata_gene
      - Metadata_negcon_or_other
      - Metadata_negcon_control_type_trimmed
  variable_groups:
    value:
      - xArea: _AreaShape_Area$
      - xShape: AreaShape
      - xNeigh: Neighbors
      - xCorr: Correlation
      - Tex_AGP: ((Texture|Granularity|RadialDistribution)_.*_(AGP))
      - Tex_DNA: ((Texture|Granularity|RadialDistribution)_.*_(DNA))
      - Tex_ER: ((Texture|Granularity|RadialDistribution)_.*_(ER))
      - Tex_Mito: ((Texture|Granularity|RadialDistribution)_.*_(Mito))
      - Tex_RNA: ((Texture|Granularity|RadialDistribution)_.*_(RNA))
      - Int_AGP: ((Intensity)_.*_(AGP))
      - Int_DNA: ((Intensity)_.*_(DNA))
      - Int_ER: ((Intensity)_.*_(ER))
      - Int_Mito: ((Intensity)_.*_(Mito))
      - Int_RNA: ((Intensity)_.*_(RNA))
---

# Setup

```{r message=FALSE}
library(magrittr)
library(tidyverse)
library(glue)
library(arrow)
library(matric)
```


```{r}
batch <- params$batch
futile.logger::flog.info(glue("Batch = {batch}"))
```

```{r}
experiment <- as.data.frame(params$experiment)
```

```{r}
experiment_tag <-
  experiment %>%
  unite("experiment_tag", everything()) %>%
  pull("experiment_tag") %>%
  sort() %>%
  paste(collapse = "_")

futile.logger::flog.info(glue("Experiment tag = {experiment_tag}"))
```
```{r message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glue)
library(magrittr)
library(stringr)
library(tidyverse)
```

## Prepare load_data 

```{r prepare_load_data, message=FALSE}
load_data <- 
  list.files("../load_data_csv/", pattern = "load_data.csv", full.names = T, recursive = T)  %>%
  map_df(read_csv)
```


```{r}
load_data %>% write_parquet("~/Desktop/load_data.parquet")
```

```{r}
load_data <- read_parquet("~/Desktop/load_data.parquet")
```


```{r message=FALSE}
convert_to_s3_url <- function(pathname, filename)  {
  file.path(
    pathname %>%
      str_replace(
        "/home/ubuntu/bucket",
        "https://s3.amazonaws.com/jump-cellpainting") %>%
      str_replace(
        "2019_07_11_JUMP-CP/2020_11_04_CPJUMP1/images/",
        "2019_07_11_JUMP-CP-pilots/2020_11_04_CPJUMP1/images/"),
    filename
  )
  
}

channels <- c("DNA", "ER", "RNA", "AGP", "Mito")

for (channel in channels) {
  url_sym <- rlang::sym(str_c("URL_Orig", channel))
  
  path_sym <- rlang::sym(str_c("PathName_Orig", channel))
   
  file_sym <- rlang::sym(str_c("FileName_Orig", channel))
   
  load_data %<>% 
    mutate(!!url_sym := convert_to_s3_url((!!path_sym), (!!file_sym)))
  
}
```

## Resolve with collated data

Plates that are not present in the collated file will be dropped

```{r}
profiles_metadata <-
  read_parquet("../collated/2020_11_04_CPJUMP1/2020_11_04_CPJUMP1_all_augmented.parquet",
              col_select = matches("Metadata_"))

load_data <-
  load_data %>%
  inner_join(profiles_metadata)
```


```{r rows.print=20}
load_data %>% 
  distinct(across(all_of(c(params$nesting_level_0, "Metadata_Plate")))) %>%
  arrange(across(all_of(params$nesting_level_0))) %>%
  group_by(across(all_of(params$nesting_level_0))) %>%
  tally()
```


## Sample down to the selected experiment

```{r}
load_data <-
  load_data %>%
  inner_join(experiment)

load_data %>% 
  distinct(across(all_of(c(params$nesting_level_0, "Metadata_Plate")))) %>%
  arrange(across(all_of(params$nesting_level_0))) %>%
  group_by(across(all_of(params$nesting_level_0))) %>%
  tally()
```


## Sample one well per perturbation per plate

```{r}
set.seed(5)

load_data <-
  load_data %>%
  group_by(Metadata_Plate, Metadata_broad_sample) %>%
  sample_n(1) %>%
  ungroup()
```

## Select a fixed field (a.k.a site)

```{r}
fieldIDs <- data.frame(Metadata_FieldID = c(3, 5))

load_data <-
  load_data %>%
  inner_join(fieldIDs, by = "Metadata_FieldID")
```

## Prune columns

```{r}
filenames_header <- paste0("FileName_Orig", channels)

load_data <- 
  load_data %>%
  select(matches("^Metadata"), matches("^URL"), matches("^FileName_Orig"))
```


```{r}
load_data$Metadata_Batch <- params$batch
```


```{r}
prefix <- "https://s3.amazonaws.com/jump-cellpainting/projects/2019_07_11_JUMP-CP-pilots"

# s3://imaging-platform/projects/2018_06_05_cmQTL/workspace/analysis/2019_06_10_Batch3/PLATE/analysis/PLATE-WELL-SITE/outlines/WELL_sSITE--nuclei_outlines.png 
# s3://imaging-platform/projects/2018_06_05_cmQTL/workspace/analysis/2019_06_10_Batch3/PLATE/analysis/PLATE-WELL-SITE/outlines/WELL_sSITE--cell_outlines.png.

nuclei_suffix <- "nuclei_outlines.png"
cell_suffix <- "cell_outlines.png"

load_data %<>%
  mutate(URL_nuclei_outlines = 
           file.path(
             prefix,
             "workspace",
             "analysis",
             Metadata_Batch,
             Metadata_Plate,
             "analysis",
             paste(Metadata_Plate, Metadata_Well, Metadata_FieldID, sep = "-"),
             "outlines",
             glue("{Metadata_Well}_s{Metadata_FieldID}--{nuclei_suffix}")
           )
         ) %>%
  mutate(URL_cell_outlines = 
           file.path(
             prefix,
             "workspace",
             "analysis",
             Metadata_Batch,
             Metadata_Plate,
             "analysis",
             paste(Metadata_Plate, Metadata_Well, Metadata_FieldID, sep = "-"),
             "outlines",
             glue("{Metadata_Well}_s{Metadata_FieldID}--{cell_suffix}")
           )
         )
```


```{r}
load_data_pivoted <-
  load_data %>%
  select(Metadata_Plate,  Metadata_Well, matches("^URL_")) %>%
  gather(Metadata_Channel, URL, -Metadata_Plate, -Metadata_Well) %>%
  mutate(filename = basename(URL)) %>%
  select(Metadata_Plate, Metadata_Well, Metadata_Channel, filename, URL)

load_data_pivoted %>% 
  write_csv(glue("{batch}/{batch}_{experiment_tag}_sample_images.csv"))

```

```{r}
load_data %>%
  select(matches("^Metadata"),  matches("^FileName_Orig")) %>%
  write_csv(glue("{batch}/{batch}_{experiment_tag}_sample_images_metadata.csv"))
```

Run this on command line to download the images:

```{sh eval=FALSE}
IMAGE_DIR=/tmp/2020_11_04_CPJUMP1

mkdir -p $IMAGE_DIR

cut -d"," -f1 2020_11_04_CPJUMP1/sample_images.csv | grep -v Metadata_Plate| sort -u > /tmp/plates.txt

parallel -a /tmp/plates.txt --no-run-if-empty mkdir -p $IMAGE_DIR/{} 

parallel \
 --header ".*\n" \
 -C "," \
 -a data/sample_images.csv \
 --eta \
 --joblog ${IMAGE_DIR}/download.log \
 wget -q -O ${IMAGE_DIR}/{1}/{4} {5}
  
```

